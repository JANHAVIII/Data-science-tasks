{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48715afa",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1682a3a",
   "metadata": {},
   "source": [
    "Splitting Criteria :\n",
    "    \n",
    "    1. Entropy\n",
    "    2. gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e88b6",
   "metadata": {},
   "source": [
    "# 1. Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overcast = 4Y and 0N\n",
    "Rainy    = 3Y and 2N\n",
    "Sunny    = 2Y and 3N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ec914",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gini(Outlook == Overcast) = 0\n",
    "Gini(Outlook == Rainy) = 0.48\n",
    "Gini(Outlook == Sunny) = 0.48\n",
    "\n",
    "Calculate weighted avg of gini for outlook attribute:\n",
    "    \n",
    "Gini(Outlook) = (4/14) * 0 + (5/14) * 0.48 + (5/14) * 0.48 = 0.342\n",
    "Gini(Temperature) = 0.438\n",
    "Gini(Humidity) = 0.366\n",
    "Gini(Windy)  = 0.428\n",
    "\n",
    "Select Lowest/Minumum value of GINI for selecting root/ Decision Node\n",
    "\n",
    "Outlook Willn be the decision node"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ea04898",
   "metadata": {},
   "source": [
    "Information Gain = Maximumn Value for selecting the Best root node/Decision Node\n",
    "Gini Index / Gini Impurity = Minimum Value for selecting Decision Node"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04b09db1",
   "metadata": {},
   "source": [
    "ID3 (Iterative Dechotomiser - 3) uses Information gain tom find best decision node\n",
    "CART (Classification and Regression Tree) Uses Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab29b89",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b61b21",
   "metadata": {},
   "source": [
    "# Advantages :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcd471fd",
   "metadata": {},
   "source": [
    "1. It is Useful for classification and Regression\n",
    "2. It is easy to understand, Implement and Visualize\n",
    "3. It is Non - Parametric algorithm\n",
    "4. It is not sensetive to Outliers / No Impact Outliers\n",
    "5. Best For non - Linear Relationship\n",
    "6. Scaling is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5925f08",
   "metadata": {},
   "source": [
    "# Disadvantages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b98e6b71",
   "metadata": {},
   "source": [
    "1. Decision tree most often get overfitted / Overfitting\n",
    "2. We can see low bias and high variance in decision tree most of the time.\n",
    "3. It is unstable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2317d4",
   "metadata": {},
   "source": [
    "# How to Avoid Overfitting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9017c16",
   "metadata": {},
   "source": [
    "1. We can use Hyperparameter Tuning:\n",
    "    \n",
    "    Max_Depth >> None\n",
    "    Min_Samples_Split >> (Branch Node)\n",
    "    Min_Samples_Leaf  >> (Leaf Node)\n",
    "    Criteria  >> 'gini' ('Entropy')\n",
    "    \n",
    "2. We can avoide overfitting by using Ensable Technique\n",
    "    1. Random Forest\n",
    "    2. AdaBoost\n",
    "    \n",
    "3. Pruning : (ccp_alpha)\n",
    "    \n",
    "   1. It reduces the size of decision tree by removing the Branches that do not provide power to classify\n",
    "   2. We can reduce the branches of our tree\n",
    "   \n",
    "ccp_alpha = Cost Complexity Pruning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
